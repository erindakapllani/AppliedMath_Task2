{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_sm\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from typing import Any, List, Mapping, Tuple\n",
        "\n",
        "\n",
        "class QuestionGenerator:\n",
        "    \"\"\"A transformer-based NLP system for generating reading comprehension-style questions from\n",
        "    texts. It can generate full sentence questions, multiple choice questions, or a mix of the\n",
        "    two styles.\n",
        "\n",
        "    To filter out low quality questions, questions are assigned a score and ranked once they have\n",
        "    been generated. Only the top k questions will be returned. This behaviour can be turned off\n",
        "    by setting use_evaluator=False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "\n",
        "        QG_PRETRAINED = \"iarfmoose/t5-base-question-generator\"\n",
        "        self.ANSWER_TOKEN = \"<answer>\"\n",
        "        self.CONTEXT_TOKEN = \"<context>\"\n",
        "        self.SEQ_LENGTH = 512\n",
        "\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.qg_tokenizer = AutoTokenizer.from_pretrained(\n",
        "            QG_PRETRAINED, use_fast=False)\n",
        "        self.qg_model = AutoModelForSeq2SeqLM.from_pretrained(QG_PRETRAINED)\n",
        "        self.qg_model.to(self.device)\n",
        "        self.qg_model.eval()\n",
        "\n",
        "        self.qa_evaluator = QAEvaluator()\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        article: str,\n",
        "        use_evaluator: bool = True,\n",
        "        num_questions: bool = None,\n",
        "        answer_style: str = \"all\"\n",
        "    ) -> List:\n",
        "        \"\"\"Takes an article and generates a set of question and answer pairs. If use_evaluator\n",
        "        is True then QA pairs will be ranked and filtered based on their quality. answer_style\n",
        "        should selected from [\"all\", \"sentences\", \"multiple_choice\"].\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Generating questions...\\n\")\n",
        "\n",
        "        qg_inputs, qg_answers = self.generate_qg_inputs(article, answer_style)\n",
        "        generated_questions = self.generate_questions_from_inputs(qg_inputs)\n",
        "\n",
        "        message = \"{} questions doesn't match {} answers\".format(\n",
        "            len(generated_questions), len(qg_answers)\n",
        "        )\n",
        "        assert len(generated_questions) == len(qg_answers), message\n",
        "\n",
        "        if use_evaluator:\n",
        "            print(\"Evaluating QA pairs...\\n\")\n",
        "            encoded_qa_pairs = self.qa_evaluator.encode_qa_pairs(\n",
        "                generated_questions, qg_answers\n",
        "            )\n",
        "            scores = self.qa_evaluator.get_scores(encoded_qa_pairs)\n",
        "\n",
        "            if num_questions:\n",
        "                qa_list = self._get_ranked_qa_pairs(\n",
        "                    generated_questions, qg_answers, scores, num_questions\n",
        "                )\n",
        "            else:\n",
        "                qa_list = self._get_ranked_qa_pairs(\n",
        "                    generated_questions, qg_answers, scores\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            print(\"Skipping evaluation step.\\n\")\n",
        "            qa_list = self._get_all_qa_pairs(generated_questions, qg_answers)\n",
        "\n",
        "        return qa_list\n",
        "\n",
        "    def generate_qg_inputs(self, text: str, answer_style: str) -> Tuple[List[str], List[str]]:\n",
        "        \"\"\"Given a text, returns a list of model inputs and a list of corresponding answers.\n",
        "        Model inputs take the form \"answer_token <answer text> context_token <context text>\" where\n",
        "        the answer is a string extracted from the text, and the context is the wider text surrounding\n",
        "        the context.\n",
        "        \"\"\"\n",
        "\n",
        "        VALID_ANSWER_STYLES = [\"all\", \"sentences\", \"multiple_choice\"]\n",
        "\n",
        "        if answer_style not in VALID_ANSWER_STYLES:\n",
        "            raise ValueError(\n",
        "                \"Invalid answer style {}. Please choose from {}\".format(\n",
        "                    answer_style, VALID_ANSWER_STYLES\n",
        "                )\n",
        "            )\n",
        "\n",
        "        inputs = []\n",
        "        answers = []\n",
        "\n",
        "        if answer_style == \"sentences\" or answer_style == \"all\":\n",
        "            segments = self._split_into_segments(text)\n",
        "\n",
        "            for segment in segments:\n",
        "                sentences = self._split_text(segment)\n",
        "                prepped_inputs, prepped_answers = self._prepare_qg_inputs(\n",
        "                    sentences, segment\n",
        "                )\n",
        "                inputs.extend(prepped_inputs)\n",
        "                answers.extend(prepped_answers)\n",
        "\n",
        "        if answer_style == \"multiple_choice\" or answer_style == \"all\":\n",
        "            sentences = self._split_text(text)\n",
        "            prepped_inputs, prepped_answers = self._prepare_qg_inputs_MC(\n",
        "                sentences\n",
        "            )\n",
        "            inputs.extend(prepped_inputs)\n",
        "            answers.extend(prepped_answers)\n",
        "\n",
        "        return inputs, answers\n",
        "\n",
        "    def generate_questions_from_inputs(self, qg_inputs: List) -> List[str]:\n",
        "        \"\"\"Given a list of concatenated answers and contexts, with the form:\n",
        "        \"answer_token <answer text> context_token <context text>\", generates a list of\n",
        "        questions.\n",
        "        \"\"\"\n",
        "        generated_questions = []\n",
        "\n",
        "        for qg_input in qg_inputs:\n",
        "            question = self._generate_question(qg_input)\n",
        "            generated_questions.append(question)\n",
        "\n",
        "        return generated_questions\n",
        "\n",
        "    def _split_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Splits the text into sentences, and attempts to split or truncate long sentences.\"\"\"\n",
        "        MAX_SENTENCE_LEN = 128\n",
        "        sentences = re.findall(\".*?[.!\\?]\", text)\n",
        "        cut_sentences = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            if len(sentence) > MAX_SENTENCE_LEN:\n",
        "                cut_sentences.extend(re.split(\"[,;:)]\", sentence))\n",
        "\n",
        "        # remove useless post-quote sentence fragments\n",
        "        cut_sentences = [s for s in sentences if len(s.split(\" \")) > 5]\n",
        "        sentences = sentences + cut_sentences\n",
        "\n",
        "        return list(set([s.strip(\" \") for s in sentences]))\n",
        "\n",
        "    def _split_into_segments(self, text: str) -> List[str]:\n",
        "        \"\"\"Splits a long text into segments short enough to be input into the transformer network.\n",
        "        Segments are used as context for question generation.\n",
        "        \"\"\"\n",
        "        MAX_TOKENS = 490\n",
        "        paragraphs = text.split(\"\\n\")\n",
        "        tokenized_paragraphs = [\n",
        "            self.qg_tokenizer(p)[\"input_ids\"] for p in paragraphs if len(p) > 0\n",
        "        ]\n",
        "        segments = []\n",
        "\n",
        "        while len(tokenized_paragraphs) > 0:\n",
        "            segment = []\n",
        "\n",
        "            while len(segment) < MAX_TOKENS and len(tokenized_paragraphs) > 0:\n",
        "                paragraph = tokenized_paragraphs.pop(0)\n",
        "                segment.extend(paragraph)\n",
        "            segments.append(segment)\n",
        "\n",
        "        return [self.qg_tokenizer.decode(s, skip_special_tokens=True) for s in segments]\n",
        "\n",
        "    def _prepare_qg_inputs(\n",
        "        self,\n",
        "        sentences: List[str],\n",
        "        text: str\n",
        "    ) -> Tuple[List[str], List[str]]:\n",
        "        \"\"\"Uses sentences as answers and the text as context. Returns a tuple of (model inputs, answers).\n",
        "        Model inputs are \"answer_token <answer text> context_token <context text>\"\n",
        "        \"\"\"\n",
        "        inputs = []\n",
        "        answers = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            qg_input = f\"{self.ANSWER_TOKEN} {sentence} {self.CONTEXT_TOKEN} {text}\"\n",
        "            inputs.append(qg_input)\n",
        "            answers.append(sentence)\n",
        "\n",
        "        return inputs, answers\n",
        "\n",
        "    def _prepare_qg_inputs_MC(self, sentences: List[str]) -> Tuple[List[str], List[str]]:\n",
        "        \"\"\"Performs NER on the text, and uses extracted entities are candidate answers for multiple-choice\n",
        "        questions. Sentences are used as context, and entities as answers. Returns a tuple of (model inputs, answers).\n",
        "        Model inputs are \"answer_token <answer text> context_token <context text>\"\n",
        "        \"\"\"\n",
        "        spacy_nlp = en_core_web_sm.load()\n",
        "        docs = list(spacy_nlp.pipe(sentences, disable=[\"parser\"]))\n",
        "        inputs_from_text = []\n",
        "        answers_from_text = []\n",
        "\n",
        "        for doc, sentence in zip(docs, sentences):\n",
        "            entities = doc.ents\n",
        "            if entities:\n",
        "\n",
        "                for entity in entities:\n",
        "                    qg_input = f\"{self.ANSWER_TOKEN} {entity} {self.CONTEXT_TOKEN} {sentence}\"\n",
        "                    answers = self._get_MC_answers(entity, docs)\n",
        "                    inputs_from_text.append(qg_input)\n",
        "                    answers_from_text.append(answers)\n",
        "\n",
        "        return inputs_from_text, answers_from_text\n",
        "\n",
        "    def _get_MC_answers(self, correct_answer: Any, docs: Any) -> List[Mapping[str, Any]]:\n",
        "        \"\"\"Finds a set of alternative answers for a multiple-choice question. Will attempt to find\n",
        "        alternatives of the same entity type as correct_answer if possible.\n",
        "        \"\"\"\n",
        "        entities = []\n",
        "\n",
        "        for doc in docs:\n",
        "            entities.extend([{\"text\": e.text, \"label_\": e.label_}\n",
        "                            for e in doc.ents])\n",
        "\n",
        "        # remove duplicate elements\n",
        "        entities_json = [json.dumps(kv) for kv in entities]\n",
        "        pool = set(entities_json)\n",
        "        num_choices = (\n",
        "            min(4, len(pool)) - 1\n",
        "        )  # -1 because we already have the correct answer\n",
        "\n",
        "        # add the correct answer\n",
        "        final_choices = []\n",
        "        correct_label = correct_answer.label_\n",
        "        final_choices.append({\"answer\": correct_answer.text, \"correct\": True})\n",
        "        pool.remove(\n",
        "            json.dumps({\"text\": correct_answer.text,\n",
        "                       \"label_\": correct_answer.label_})\n",
        "        )\n",
        "\n",
        "        # find answers with the same NER label\n",
        "        matches = [e for e in pool if correct_label in e]\n",
        "\n",
        "        # if we don't have enough then add some other random answers\n",
        "        if len(matches) < num_choices:\n",
        "            choices = matches\n",
        "            pool = pool.difference(set(choices))\n",
        "            choices.extend(random.sample(pool, num_choices - len(choices)))\n",
        "        else:\n",
        "            choices = random.sample(matches, num_choices)\n",
        "\n",
        "        choices = [json.loads(s) for s in choices]\n",
        "\n",
        "        for choice in choices:\n",
        "            final_choices.append({\"answer\": choice[\"text\"], \"correct\": False})\n",
        "\n",
        "        random.shuffle(final_choices)\n",
        "        return final_choices\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _generate_question(self, qg_input: str) -> str:\n",
        "        \"\"\"Takes qg_input which is the concatenated answer and context, and uses it to generate\n",
        "        a question sentence. The generated question is decoded and then returned.\n",
        "        \"\"\"\n",
        "        encoded_input = self._encode_qg_input(qg_input)\n",
        "        output = self.qg_model.generate(input_ids=encoded_input[\"input_ids\"])\n",
        "        question = self.qg_tokenizer.decode(\n",
        "            output[0],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        return question\n",
        "\n",
        "    def _encode_qg_input(self, qg_input: str) -> torch.tensor:\n",
        "        \"\"\"Tokenizes a string and returns a tensor of input ids corresponding to indices of tokens in\n",
        "        the vocab.\n",
        "        \"\"\"\n",
        "        return self.qg_tokenizer(\n",
        "            qg_input,\n",
        "            padding='max_length',\n",
        "            max_length=self.SEQ_LENGTH,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(self.device)\n",
        "\n",
        "    def _get_ranked_qa_pairs(\n",
        "        self, generated_questions: List[str], qg_answers: List[str], scores, num_questions: int = 10\n",
        "    ) -> List[Mapping[str, str]]:\n",
        "        \"\"\"Ranks generated questions according to scores, and returns the top num_questions examples.\n",
        "        \"\"\"\n",
        "        if num_questions > len(scores):\n",
        "            num_questions = len(scores)\n",
        "            print((\n",
        "                f\"\\nWas only able to generate {num_questions} questions.\",\n",
        "                \"For more questions, please input a longer text.\")\n",
        "            )\n",
        "\n",
        "        qa_list = []\n",
        "\n",
        "        for i in range(num_questions):\n",
        "            index = scores[i]\n",
        "            qa = {\n",
        "                \"question\": generated_questions[index].split(\"?\")[0] + \"?\",\n",
        "                \"answer\": qg_answers[index]\n",
        "            }\n",
        "            qa_list.append(qa)\n",
        "\n",
        "        return qa_list\n",
        "\n",
        "    def _get_all_qa_pairs(self, generated_questions: List[str], qg_answers: List[str]):\n",
        "        \"\"\"Formats question and answer pairs without ranking or filtering.\"\"\"\n",
        "        qa_list = []\n",
        "\n",
        "        for question, answer in zip(generated_questions, qg_answers):\n",
        "            qa = {\n",
        "                \"question\": question.split(\"?\")[0] + \"?\",\n",
        "                \"answer\": answer\n",
        "            }\n",
        "            qa_list.append(qa)\n",
        "\n",
        "        return qa_list\n",
        "\n",
        "\n",
        "class QAEvaluator:\n",
        "    \"\"\"Wrapper for a transformer model which evaluates the quality of question-answer pairs.\n",
        "    Given a QA pair, the model will generate a score. Scores can be used to rank and filter\n",
        "    QA pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "\n",
        "        QAE_PRETRAINED = \"iarfmoose/bert-base-cased-qa-evaluator\"\n",
        "        self.SEQ_LENGTH = 512\n",
        "\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.qae_tokenizer = AutoTokenizer.from_pretrained(QAE_PRETRAINED)\n",
        "        self.qae_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            QAE_PRETRAINED\n",
        "        )\n",
        "        self.qae_model.to(self.device)\n",
        "        self.qae_model.eval()\n",
        "\n",
        "    def encode_qa_pairs(self, questions: List[str], answers: List[str]) -> List[torch.tensor]:\n",
        "        \"\"\"Takes a list of questions and a list of answers and encodes them as a list of tensors.\"\"\"\n",
        "        encoded_pairs = []\n",
        "\n",
        "        for question, answer in zip(questions, answers):\n",
        "            encoded_qa = self._encode_qa(question, answer)\n",
        "            encoded_pairs.append(encoded_qa.to(self.device))\n",
        "\n",
        "        return encoded_pairs\n",
        "\n",
        "    def get_scores(self, encoded_qa_pairs: List[torch.tensor]) -> List[float]:\n",
        "        \"\"\"Generates scores for a list of encoded QA pairs.\"\"\"\n",
        "        scores = {}\n",
        "\n",
        "        for i in range(len(encoded_qa_pairs)):\n",
        "            scores[i] = self._evaluate_qa(encoded_qa_pairs[i])\n",
        "\n",
        "        return [\n",
        "            k for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
        "        ]\n",
        "\n",
        "    def _encode_qa(self, question: str, answer: str) -> torch.tensor:\n",
        "        \"\"\"Concatenates a question and answer, and then tokenizes them. Returns a tensor of\n",
        "        input ids corresponding to indices in the vocab.\n",
        "        \"\"\"\n",
        "        if type(answer) is list:\n",
        "            for a in answer:\n",
        "                if a[\"correct\"]:\n",
        "                    correct_answer = a[\"answer\"]\n",
        "        else:\n",
        "            correct_answer = answer\n",
        "\n",
        "        return self.qae_tokenizer(\n",
        "            text=question,\n",
        "            text_pair=correct_answer,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.SEQ_LENGTH,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _evaluate_qa(self, encoded_qa_pair: torch.tensor) -> float:\n",
        "        \"\"\"Takes an encoded QA pair and returns a score.\"\"\"\n",
        "        output = self.qae_model(**encoded_qa_pair)\n",
        "        return output[0][0][1]\n",
        "\n",
        "\n",
        "def print_qa(qa_list: List[Mapping[str, str]], show_answers: bool = True) -> None:\n",
        "    \"\"\"Formats and prints a list of generated questions and answers.\"\"\"\n",
        "\n",
        "    for i in range(len(qa_list)):\n",
        "        # wider space for 2 digit q nums\n",
        "        space = \" \" * int(np.where(i < 9, 3, 4))\n",
        "\n",
        "        print(f\"{i + 1}) Q: {qa_list[i]['question']}\")\n",
        "\n",
        "        answer = qa_list[i][\"answer\"]\n",
        "\n",
        "        # print a list of multiple choice answers\n",
        "        if type(answer) is list:\n",
        "\n",
        "            if show_answers:\n",
        "                print(\n",
        "                    f\"{space}A: 1. {answer[0]['answer']} \"\n",
        "                    f\"{np.where(answer[0]['correct'], '(correct)', '')}\"\n",
        "                )\n",
        "                for j in range(1, len(answer)):\n",
        "                    print(\n",
        "                        f\"{space + '   '}{j + 1}. {answer[j]['answer']} \"\n",
        "                        f\"{np.where(answer[j]['correct']==True,'(correct)', '')}\"\n",
        "                    )\n",
        "\n",
        "            else:\n",
        "                print(f\"{space}A: 1. {answer[0]['answer']}\")\n",
        "                for j in range(1, len(answer)):\n",
        "                    print(f\"{space + '   '}{j + 1}. {answer[j]['answer']}\")\n",
        "\n",
        "            print(\"\")\n",
        "\n",
        "        # print full sentence answers\n",
        "        else:\n",
        "            if show_answers:\n",
        "                print(f\"{space}A: {answer}\\n\")"
      ],
      "metadata": {
        "id": "QRdhXat6a1Qc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "\n",
        "# Clone the question generator repository\n",
        "!git clone https://github.com/erindakapllani/question_generator/\n",
        "%cd question_generator/\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from questiongenerator import QuestionGenerator, print_qa\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "# Ensure GPU is being used\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "assert device == torch.device('cuda'), \"Not using CUDA. Set: Runtime > Change runtime type > Hardware Accelerator: GPU\"\n",
        "\n",
        "# Initialize the Question Generator\n",
        "qg = QuestionGenerator()\n",
        "\n",
        "import os\n",
        "\n",
        "# List all files in the 'articles' folder\n",
        "article_files = os.listdir('articles')\n",
        "article_contents = []\n",
        "# Read contents of each file\n",
        "for file_name in article_files:\n",
        "    file_path = os.path.join('articles', file_name)\n",
        "    with open(file_path, 'r') as file:\n",
        "        article_contents.append(file.read())\n",
        "\n",
        "# Combine all article contents into a single string\n",
        "combined_article = \"\\n\".join(article_contents)\n",
        "\n",
        "\n",
        "# Generate questions\n",
        "qa_list = qg.generate(article, num_questions=37, answer_style='all')\n",
        "print_qa(qa_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlEegWNcilGZ",
        "outputId": "9468dc11-fecb-49e8-9ff3-a1979c6362aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Cloning into 'question_generator'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 106 (delta 48), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 416.68 KiB | 10.16 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/question_generator/question_generator/question_generator/question_generator/question_generator/question_generator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating questions...\n",
            "\n",
            "Evaluating QA pairs...\n",
            "\n",
            "1) Q: What are the types of inspections that are required to determine systemic problems in licensee activities?\n",
            "   A: Type II inspections are point-in-time, snapshot verifications of licensee activities, which focus on outputs or performance of licensee programs, processes and practices.\n",
            "\n",
            "2) Q: What is the role of Type II inspections in determining systemic problems in licensee programs?\n",
            "   A: Findings from Type II inspections play a key role in identifying where a Type I inspection may be required to determine systemic problems in licensee programs, processes or practices.\n",
            "\n",
            "3) Q: The proposed amendments to the Class II regulations are being worked on in preparation for the formal pre?\n",
            "   A: Justice Canada and CNSC are working on the wording for the proposed amendments to the Class II regulations in preparation for the formal pre-consultation.\n",
            "\n",
            "4) Q: What is the reason why CNSC has experienced a substantial increase in its workload?\n",
            "   A: As a result of growing activity in all areas of the nuclear sector over the past several years, CNSC has experienced a substantial increase in its workload in most areas of its responsibility.\n",
            "\n",
            "5) Q: What did CNSC do to ensure that it could perform its regulatory responsibilities?\n",
            "   A: To ensure that CNSC can perform its regulatory licensing and compliance responsibilities associated with this growth, we refocused efforts to respond to these developments and the proposed plans for new uranium mining and processing, while ensuring safety and security of existing facilities.\n",
            "\n",
            "6) Q: What is the current status of CNSC's revenue spending authority?\n",
            "   A: This authority is being phased in over a two-year period, with full implementation of revenue spending authority for all cost-recoverable activities effective for 2009-2010.\n",
            "\n",
            "7) Q: What is the role of CNSC in ensuring the safety and security of high-risk?\n",
            "   A: As the first country with such robust inventory tracking, Canada has set an international example for ensuring the safety and security of high-risk radioactive sealed sources.\n",
            "\n",
            "8) Q: What was the role of CNSC in enforcing compliance with nuclear substances?\n",
            "   A: Assuring Canadians of the Continuing Compliance and Safety Performance of Licensees CNSC’s role in enforcing compliance with nuclear substance-related licences was illustrated in June 2007, when the Commission Tribunal concluded that 588972 Alberta Ltd.\n",
            "\n",
            "9) Q: What is the best way to improve the safety of Canadians?\n",
            "   A: These are just a few examples of the excellent work CNSC has undertaken over the past year to enhance the health, safety and security of Canadians and the environment.\n",
            "\n",
            "10) Q: What is the purpose of the 2007 Staff Report on the Safety Performance of the Canadian Nuclear Power Industry?\n",
            "    A: Assure Canadians of the continuing compliance and safety performance of licensees Execute baseline compliance program requirements As stated in the 2007 Staff Report on the Safety Performance of the Canadian Nuclear Power Industry (Industry Report), CNSC concluded that overall, the Canadian nuclear power plant industry operated safely.\n",
            "\n",
            "11) Q: What is the reason why CNSC has experienced rapid growth in the nuclear sector?\n",
            "    A: Recently, due to growth in the nuclear sector, CNSC has experienced rapidly increasing demand for its licensing, licensee certification and pre-project power plant design review activities, and consequently explored alternate funding mechanisms to meet future resource requirements.\n",
            "\n",
            "12) Q: What were the key regulatory documents to address gaps in regulatory requirements and guidance?\n",
            "    A: new power reactors, expansion of mines and processing facilities, fire protection, aging of power reactors, and integrated The CNSC published the following key regulatory documents to provide guidelines to address gaps in regulatory requirements and guidance: • RD-360, Life Extension of Nuclear Power Plants • RD-204, Certification of Persons Working at Nuclear Power Plants • RD-310, Safety Analysis for Nuclear Power 4A total of three regulatory proposals were made by the Commission in 2007-2008.\n",
            "\n",
            "13) Q: What did CNSC do to maintain a productive working relationship with the bargaining agent?\n",
            "    A: CNSC has also worked to maintain a productive working relationship, through consultations with the bargaining agent and with employees that are not represented.\n",
            "\n",
            "14) Q: What is the role of the Commission Tribunal?\n",
            "    A: CNSC’s mandate, responsibilities and powers are set out in the NSCA and are elaborated in the Canadian Nuclear Safety Commission Rules of Procedure and the Canadian Nuclear Safety Commission By-laws.\n",
            "\n",
            "15) Q: What is the CNSC’s response to the growing demand for nuclear energy?\n",
            "    A: These trends are all shaping an increased demand for nuclear energy and materials, and CNSC is responding to meet the challenges associated with regulating an expanding nuclear industry.\n",
            "\n",
            "16) Q: What is the role of the Commission Tribunal?\n",
            "    A: Through the NSCA, regulations, associated regulatory documents, licences and licence conditions, CNSC regulates the entire Canadian nuclear cycle and all aspects of nuclear safety.\n",
            "\n",
            "17) Q: What was the CNSC’s response to the request for additional funding?\n",
            "    A: In addition, after the receipt of two applications for site licensing for construction of new power reactors in Canada, CNSC requested and received approval for incremental funding in 2006-2007 that included funding of $5.\n",
            "\n",
            "18) Q: What was the reason for the decontamination of the Enviropac building?\n",
            "    A: Further investigation of the Enviropac building, in March 2008, revealed that the radioactive contamination was greater than initially expected, and that it was present in additional areas of the facility.\n",
            "\n",
            "19) Q: What is the purpose of the CNSC's MOUs with regulatory counterparts around?\n",
            "    A: The CNSC maintains MOUs with regulatory counterparts around the world, in order to strengthen safety standards with respect to nuclear facilities, through technical cooperation and information exchanges in nuclear regulatory matters.\n",
            "\n",
            "20) Q: What is the role of CNSC in regulating the growing demand for nuclear power?\n",
            "    A: As part of its increased focus on new nuclear power plants, CNSC has begun modernizing its regulatory framework to bring it in line with current international standards and to apply these standards to projects for building new nuclear plants.\n",
            "\n",
            "21) Q: What is the most important thing to do when CNSC's workload increases?\n",
            "    A: When its workload increases, CNSC applies to the Treasury Board Secretariat to increase its cost-recoverable expenditures and related fee revenues or to receive new program funding.\n",
            "\n",
            "22) Q: What did CNSC do to improve the safety of the nuclear industry?\n",
            "    A: In its Industry Report overview, CNSC personnel concluded that the nuclear power plant industry operated safely throughout 2007.\n",
            "\n",
            "23) Q: What is the purpose of the RPP?\n",
            "    A: CNSC aims to renew these agreements without further delay, and to incorporate automatic renewal clauses in all MOUs.\n",
            "\n",
            "24) Q: What is the purpose of the RPP?\n",
            "    A: CNSC renewed its MOU on nuclear regulatory cooperation with the Ministry of Science and Technology (MOST) of the Republic of Korea, which benefits the CNSC by providing enhanced access to MOST’s scientific and technical expertise.\n",
            "\n",
            "25) Q: What is the purpose of the Directorate of Regulatory Improvement and Major Projects Management?\n",
            "    A: To address industry growth in Canada, CNSC is creating a new Directorate of Regulatory Improvement and Major Projects Management.\n",
            "\n",
            "26) Q: What is the role of the CNSC representative in the IAEA?\n",
            "    A: The Canadian representative is also the current chair of SAGSI, a group of experts that provides advice on the technical objectives and implementation of IAEA safeguards and on the effectiveness and efficiency of specific implementation practices.\n",
            "\n",
            "27) Q: What are the key elements of the CNSC’s strategy to enforce compliance?\n",
            "    A: Develop strategies to promote/enforce compliance where licensee deficiencies have been identified, and responding to risksignificant licensee reports and findings CNSC’s security specialists conducted five Type I security inspections at Canadian nuclear power plants and at Atomic Energy of Canada Limited’s Chalk River Laboratories.\n",
            "\n",
            "28) Q: What are the latest accomplishments in the implementation of the IAEA’s verification system in?\n",
            "    A: As part of the move towards a new approach for the implementation of IAEA’s verification system in Canada, the latest accomplishments include the implementation of a new way to verify the transfer of spent fuel at multi-unit reactor stations, and significant progress in the revision of safeguards verification processes at uranium processing facilities and nuclear power reactors.\n",
            "\n",
            "29) Q: What are the changes to the Nuclear Substances and Radiation Devices Regulations?\n",
            "    A: • Revise the following regulations: o Nuclear Substances and Radiation Devices Regulations o Class II Nuclear Facilities and Prescribed Equipment Regulations o Nuclear Non-Proliferation Import and Export Control Regulations o Canadian Nuclear Safety Commission Rules of Procedure and Canadian Nuclear Safety Commission By-laws CNSC amended the Nuclear Substances and Radiation Devices Regulations and the Class II Nuclear Facilities and Prescribed Equipment Regulations, with related consequential amendments to the General Nuclear Safety and Control Regulations and the Class I Nuclear Facilities Regulations.\n",
            "\n",
            "30) Q: What was the first time CNSC consulted with the employee union?\n",
            "    A: Implementation of a First Collective Agreement After signing a first collective agreement in 2006, CNSC consulted regularly with the employee union on labour relations.\n",
            "\n",
            "31) Q: What did CNSC do to improve the safety of CANDU reactors?\n",
            "    A: These meetings focused on technical discussions about CANDU reactors (used in South Korea) and CNSC's experience in integrating international standards into domestic regulation.\n",
            "\n",
            "32) Q: What is the role of the Directorate of Regulatory Improvement and Major Projects Management?\n",
            "    A: The Directorate, expected to be established early in the 2008-2009 fiscal year, will be a single point of contact for all new build activities, consolidates the skills and expertise required to address major projects like new reactor design reviews and applications for new uranium mines and new power reactors.\n",
            "\n",
            "33) Q: What is the most important thing that CNSC has done in the past year?\n",
            "    A: The vast majority of safety areas and programs met CNSC expectations, and we are committed to maintaining and improving this good safety and security record.\n",
            "\n",
            "34) Q: What is the CNSC's Regulatory Affairs Committee?\n",
            "    A: CNSC has a non-governmental organization (NGO) Regulatory Affairs Committee, which communicates and consults with NGOs on nuclear regulatory and policy matters within its mandate.\n",
            "\n",
            "35) Q: What is the purpose of the RPP?\n",
            "    A: These arrangements provide CNSC with improved opportunities to share expertise on various issues, including CANDU reactor regulation, research reactor safety and uranium mining.\n",
            "\n",
            "36) Q: What is the purpose of the amendments to the rules of procedure and bylaws?\n",
            "    A: Canadian Nuclear Safety Commission Rules of Procedure and Canadian Nuclear Safety Commission Bylaws- Amendments • Update Rules of Procedure and By-laws to reflect best practices in the area of administrative tribunals.\n",
            "\n",
            "37) Q: What was the goal of the CNSC's 2007-2008 RPP?\n",
            "    A: 2007-2008 Resources: ($ thousands) Full-Time Equivalents Planned Spending 7,306 57 Total Authorities 7,924 Actual Spending 9,772 Outcome Measures Target 2007-2008 Results Achieved Lessons Learned and/or Challenges Level of stakeholder confidence in CNSC’s ability to regulate the use of nuclear energy and materials TBD N/A To maintain a high level of stakeholder confidence, CNSC visited, communicated and consulted with communities throughout Canada, engaged licensees, took steps to strengthen Aboriginal consultation, continued to improve public communications and the transparency of its process, and consulted with stakeholders from industry, government and nongovernmental organizations.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}