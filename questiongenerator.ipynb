{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erindakapllani/question_generator/blob/main/questiongenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_sm\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from typing import Any, List, Mapping, Tuple\n",
        "\n",
        "\n",
        "class QuestionGenerator:\n",
        "    def __init__(self) -> None:\n",
        "        QG_PRETRAINED = \"iarfmoose/t5-base-question-generator\"\n",
        "        self.ANSWER_TOKEN = \"<answer>\"\n",
        "        self.CONTEXT_TOKEN = \"<context>\"\n",
        "        self.SEQ_LENGTH = 512\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.qg_tokenizer = AutoTokenizer.from_pretrained(QG_PRETRAINED, use_fast=False)\n",
        "        self.qg_model = AutoModelForSeq2SeqLM.from_pretrained(QG_PRETRAINED)\n",
        "        self.qg_model.to(self.device)\n",
        "        self.qg_model.eval()\n",
        "\n",
        "        self.qa_evaluator = QAEvaluator()\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        article: str,\n",
        "        use_evaluator: bool = True,\n",
        "        num_questions: int = None,\n",
        "        answer_style: str = \"all\",\n",
        "        save_to_excel: bool = False,  # Add this parameter\n",
        "        excel_filename: str = \"qa_pairs.xlsx\"  # Add this parameter\n",
        "    ) -> List:\n",
        "        \"\"\"Takes an article and generates a set of question and answer pairs. If use_evaluator\n",
        "        is True then QA pairs will be ranked and filtered based on their quality. answer_style\n",
        "        should selected from [\"all\", \"sentences\", \"multiple_choice\"].\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Generating questions...\\n\")\n",
        "\n",
        "        qg_inputs, qg_answers = self.generate_qg_inputs(article, answer_style)\n",
        "        generated_questions = self.generate_questions_from_inputs(qg_inputs)\n",
        "\n",
        "        message = \"{} questions doesn't match {} answers\".format(\n",
        "            len(generated_questions), len(qg_answers)\n",
        "        )\n",
        "        assert len(generated_questions) == len(qg_answers), message\n",
        "\n",
        "        if use_evaluator:\n",
        "            print(\"Evaluating QA pairs...\\n\")\n",
        "            encoded_qa_pairs = self.qa_evaluator.encode_qa_pairs(\n",
        "                generated_questions, qg_answers\n",
        "            )\n",
        "            scores = self.qa_evaluator.get_scores(encoded_qa_pairs)\n",
        "\n",
        "            if num_questions:\n",
        "                qa_list = self._get_ranked_qa_pairs(\n",
        "                    generated_questions, qg_answers, scores, num_questions\n",
        "                )\n",
        "            else:\n",
        "                qa_list = self._get_ranked_qa_pairs(\n",
        "                    generated_questions, qg_answers, scores\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            print(\"Skipping evaluation step.\\n\")\n",
        "            qa_list = self._get_all_qa_pairs(generated_questions, qg_answers)\n",
        "\n",
        "        if save_to_excel:\n",
        "            self.save_to_excel(qa_list, excel_filename)\n",
        "\n",
        "        return qa_list\n",
        "\n",
        "    def save_to_excel(self, qa_list: List[Mapping[str, str]], filename: str) -> None:\n",
        "        \"\"\"Saves the QA pairs to an Excel file.\"\"\"\n",
        "        df = pd.DataFrame(qa_list)\n",
        "        df.to_excel(filename, index=False)\n",
        "        print(f\"QA pairs saved to {filename}\")\n",
        "\n",
        "    # Add the rest of the methods here:\n",
        "    # generate_qg_inputs, generate_questions_from_inputs, _get_ranked_qa_pairs, _get_all_qa_pairs, etc.\n",
        "\n",
        "\n",
        "class QAEvaluator:\n",
        "    # Add the class definition and methods here:\n",
        "    def encode_qa_pairs(self, questions: List[str], answers: List[str]) -> Any:\n",
        "        # Implementation of encode_qa_pairs method\n",
        "        pass\n",
        "\n",
        "    def get_scores(self, encoded_qa_pairs: Any) -> List[float]:\n",
        "        # Implementation of get_scores method\n",
        "        pass\n",
        "\n",
        "def print_qa(qa_list: List[Mapping[str, str]], show_answers: bool = True) -> None:\n",
        "    \"\"\"Formats and prints a list of generated questions and answers.\"\"\"\n",
        "\n",
        "    for i in range(len(qa_list)):\n",
        "        # wider space for 2 digit q nums\n",
        "        space = \" \" * int(np.where(i < 9, 3, 4))\n",
        "\n",
        "        print(f\"{i + 1}) Q: {qa_list[i]['question']}\")\n",
        "\n",
        "        answer = qa_list[i][\"answer\"]\n",
        "\n",
        "        # print a list of multiple choice answers\n",
        "        if type(answer) is list:\n",
        "\n",
        "            if show_answers:\n",
        "                print(\n",
        "                    f\"{space}A: 1. {answer[0]['answer']} \"\n",
        "                    f\"{np.where(answer[0]['correct'], '(correct)', '')}\"\n",
        "                )\n",
        "                for j in range(1, len(answer)):\n",
        "                    print(\n",
        "                        f\"{space + '   '}{j + 1}. {answer[j]['answer']} \"\n",
        "                        f\"{np.where(answer[j]['correct']==True,'(correct)', '')}\"\n",
        "                    )\n",
        "\n",
        "            else:\n",
        "                print(f\"{space}A: 1. {answer[0]['answer']}\")\n",
        "                for j in range(1, len(answer)):\n",
        "                    print(f\"{space + '   '}{j + 1}. {answer[j]['answer']}\")\n",
        "\n",
        "            print(\"\")\n",
        "\n",
        "        # print full sentence answers\n",
        "        else:\n",
        "            if show_answers:\n",
        "                print(f\"{space}A: {answer}\\n\")"
      ],
      "metadata": {
        "id": "QRdhXat6a1Qc"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}